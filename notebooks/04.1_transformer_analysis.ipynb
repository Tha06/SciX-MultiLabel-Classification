{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91eb6277",
   "metadata": {},
   "source": [
    "# Notebook 4.1: Transformer Model - Results and Error Analysis\n",
    "\n",
    "**Objective:** Deeply analyze the performance of the fine-tuned DistilBERT model.\n",
    "\n",
    "This notebook loads the saved artifacts from the training process and evaluates the model's performance, looking at overall metrics and specific error cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043204ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading all necessary artifacts...\n",
      "Artifacts and data loaded successfully.\n",
      "\n",
      "Generating predictions on the validation set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a99844574649efad0259902929a08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Predictions:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis setup complete. You can now run the error analysis cells.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Results Analysis Notebooks\n",
    "------------------------\n",
    "\n",
    "Comprehensive analysis of model performance:\n",
    "1. Overall metrics\n",
    "2. Per-class analysis\n",
    "3. Error cases study\n",
    "4. Performance comparison\n",
    "5. Visualization of results\n",
    "\n",
    "Analysis Types:\n",
    "- Confusion matrix per class\n",
    "- F1-score distribution\n",
    "- Sample predictions analysis\n",
    "- Error case deep dives\n",
    "\"\"\"\n",
    "\n",
    "# --- 1. Setup, Imports, and Artifact Loading ---\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- Matplotlib Style ---\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Re-define the model and dataset classes\n",
    "class SciX_HF_Dataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for our text classification task.\"\"\"\n",
    "    def __init__(self, texts, labels, tokenizer, max_len, binarizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.binarizer = binarizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label_vector = self.binarizer.transform([self.labels[item]])[0]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text, add_special_tokens=True, max_length=self.max_len,\n",
    "            return_token_type_ids=False, padding='max_length',\n",
    "            truncation=True, return_attention_mask=True, return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label_vector, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "class MultiLabelClassifier(nn.Module):\n",
    "    \"\"\"Transformer-based multi-label classifier.\"\"\"\n",
    "    def __init__(self, model_name, n_labels):\n",
    "        super(MultiLabelClassifier, self).__init__()\n",
    "        self.transformer_body = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.classifier = nn.Linear(self.transformer_body.config.hidden_size, n_labels)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.transformer_body(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = output.last_hidden_state[:, 0]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "        \n",
    "# --- Configuration and Paths ---\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "DATASET_NAME = \"adsabs/SciX_UAT_keywords\"\n",
    "TEXT_COLUMN = \"text\"\n",
    "LABEL_COLUMN = \"verified_uat_labels\"\n",
    "BATCH_SIZE = 16  # Can be larger for inference, e.g., 32\n",
    "MAX_TOKEN_LEN = 512\n",
    "\n",
    "MODEL_OUTPUT_DIR = '../models/transformer'\n",
    "MODEL_PATH = os.path.join(MODEL_OUTPUT_DIR, 'best_model_state.pth')\n",
    "THRESHOLDS_PATH = os.path.join(MODEL_OUTPUT_DIR, 'best_thresholds.npy') \n",
    "BINARIZER_PATH = os.path.join(MODEL_OUTPUT_DIR, 'label_binarizer.pkl')\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- LOAD ALL ARTIFACTS ---\n",
    "print(\"Loading all necessary artifacts...\")\n",
    "with open(BINARIZER_PATH, 'rb') as f:\n",
    "    mlb = pickle.load(f)\n",
    "num_labels = len(mlb.classes_)\n",
    "\n",
    "best_thresholds = np.load(THRESHOLDS_PATH)\n",
    "final_model = MultiLabelClassifier(MODEL_NAME, n_labels=num_labels).to(DEVICE)\n",
    "final_model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device(DEVICE)))\n",
    "final_model.eval()\n",
    "\n",
    "# --- LOAD DATA ---\n",
    "dataset = load_dataset(DATASET_NAME)\n",
    "def combine_text(examples):\n",
    "    title = examples['title'] if examples['title'] is not None else \"\"\n",
    "    abstract = examples['abstract'] if examples['abstract'] is not None else \"\"\n",
    "    examples['text'] = title + \" \" + abstract\n",
    "    return examples\n",
    "dataset = dataset.map(combine_text)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "val_dataset = SciX_HF_Dataset(\n",
    "    texts=dataset['val'][TEXT_COLUMN],\n",
    "    labels=dataset['val'][LABEL_COLUMN], \n",
    "    tokenizer=tokenizer,\n",
    "    max_len=MAX_TOKEN_LEN, \n",
    "    binarizer=mlb\n",
    ")\n",
    "print(\"Artifacts and data loaded successfully.\")\n",
    "\n",
    "\n",
    "# --- GENERATE PREDICTIONS AND PROBABILITIES ---\n",
    "print(\"\\nGenerating predictions on the validation set...\")\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(DataLoader(val_dataset, batch_size=BATCH_SIZE), desc=\"Generating Predictions\"):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        \n",
    "        outputs = final_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        \n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "        all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "all_probs = np.array(all_probs)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Generate binary predictions using the optimal per-label thresholds\n",
    "all_preds = (all_probs > best_thresholds).astype(int)\n",
    "\n",
    "# Create a DataFrame from the final report for easy querying\n",
    "transformer_report_df = pd.DataFrame(classification_report(\n",
    "    all_labels,\n",
    "    all_preds,\n",
    "    target_names=mlb.classes_,\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")).transpose()\n",
    "\n",
    "print(\"Analysis setup complete. You can now run the error analysis cells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50299b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1.2 Qualitative Error Analysis Function ---\n",
    "\n",
    "def analyze_transformer_errors(df_original, true_labels, pred_labels, probs, mlb, class_name, n_samples=3):\n",
    "    \"\"\"\n",
    "    Prints samples of False Positives and False Negatives for the Transformer model.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Error Analysis for Class: '{class_name}'\")\n",
    "    print(f\"(Threshold for this class: {best_thresholds[list(mlb.classes_).index(class_name)]:.3f})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    class_idx = list(mlb.classes_).index(class_name)\n",
    "    \n",
    "    # --- False Positives (Model predicted it, but it was wrong) ---\n",
    "    fp_mask = (pred_labels[:, class_idx] == 1) & (true_labels[:, class_idx] == 0)\n",
    "    print(f\"\\nFound {fp_mask.sum()} False Positives.\")\n",
    "    if fp_mask.sum() > 0:\n",
    "        # Find the indices of the false positives\n",
    "        fp_indices = np.where(fp_mask)[0]\n",
    "        # Sample from these indices\n",
    "        sample_indices = np.random.choice(fp_indices, size=min(n_samples, len(fp_indices)), replace=False)\n",
    "        \n",
    "        for i, idx in enumerate(sample_indices):\n",
    "            row = df_original.iloc[idx]\n",
    "            print(f\"\\n--- FP Sample #{i+1} (Original Index: {idx}) ---\")\n",
    "            print(f\"Title: {row['title']}\")\n",
    "            print(f\"  > Model's Confidence for '{class_name}': {probs[idx, class_idx]:.3f}\")\n",
    "            print(f\"  > TRUE labels: {mlb.inverse_transform(true_labels[idx].reshape(1,-1))[0]}\")\n",
    "\n",
    "    # --- False Negatives (Model missed it, but it was a true label) ---\n",
    "    fn_mask = (pred_labels[:, class_idx] == 0) & (true_labels[:, class_idx] == 1)\n",
    "    print(f\"\\nFound {fn_mask.sum()} False Negatives.\")\n",
    "    if fn_mask.sum() > 0:\n",
    "        fn_indices = np.where(fn_mask)[0]\n",
    "        sample_indices = np.random.choice(fn_indices, size=min(n_samples, len(fn_indices)), replace=False)\n",
    "\n",
    "        for i, idx in enumerate(sample_indices):\n",
    "            row = df_original.iloc[idx]\n",
    "            # Get all labels the model did predict for this sample\n",
    "            predicted_labels_indices = np.where(pred_labels[idx] == 1)[0]\n",
    "            predicted_labels = [mlb.classes_[j] for j in predicted_labels_indices]\n",
    "\n",
    "            print(f\"\\n--- FN Sample #{i+1} (Original Index: {idx}) ---\")\n",
    "            print(f\"Title: {row['title']}\")\n",
    "            print(f\"  > Model's Confidence for '{class_name}': {probs[idx, class_idx]:.3f}\")\n",
    "            print(f\"  > Model PREDICTED: {predicted_labels if predicted_labels else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b18f027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Error Analysis for Class: 'gamma-ray bursts'\n",
      "(Threshold for this class: 0.560)\n",
      "================================================================================\n",
      "\n",
      "Found 4 False Positives.\n",
      "\n",
      "--- FP Sample #1 (Original Index: 126) ---\n",
      "Title: Magnetic Field Strength Effects on Nucleosynthesis from Neutron Star Merger Outflows\n",
      "  > Model's Confidence for 'gamma-ray bursts': 0.674\n",
      "  > TRUE labels: ('accretion', 'magnetic fields', 'magnetohydrodynamical simulations', 'magnetohydrodynamics', 'neutron stars', 'nuclear astrophysics', 'nucleosynthesis', 'r-process')\n",
      "\n",
      "--- FP Sample #2 (Original Index: 2026) ---\n",
      "Title: Late-time Radio and Millimeter Observations of Superluminous Supernovae and Long Gamma-Ray Bursts: Implications for Central Engines, Fast Radio Bursts, and Obscured Star Formation\n",
      "  > Model's Confidence for 'gamma-ray bursts': 0.752\n",
      "  > TRUE labels: ('core-collapse supernovae', 'extragalactic radio sources', 'magnetars', 'radio astrometry', 'radio transient sources', 'relativistic jets', 'star formation', 'stellar physics', 'supernova remnants')\n",
      "\n",
      "--- FP Sample #3 (Original Index: 316) ---\n",
      "Title: Gamma-Rays from Kilonovae and the Cosmic Gamma-Ray Background\n",
      "  > Model's Confidence for 'gamma-ray bursts': 0.623\n",
      "  > TRUE labels: ('gamma-ray astronomy', 'gamma-ray transient sources', 'nucleosynthesis', 'r-process')\n",
      "\n",
      "Found 9 False Negatives.\n",
      "\n",
      "--- FN Sample #1 (Original Index: 895) ---\n",
      "Title: No Radio Bursts Detected from FIRST J141918.9+394036 in Green Bank Telescope Observations\n",
      "  > Model's Confidence for 'gamma-ray bursts': 0.020\n",
      "  > Model PREDICTED: ['optical observation', 'radio bursts', 'radio sources', 'radio transient sources']\n",
      "\n",
      "--- FN Sample #2 (Original Index: 1530) ---\n",
      "Title: The Improved Amati Correlations from Gaussian Copula\n",
      "  > Model's Confidence for 'gamma-ray bursts': 0.184\n",
      "  > Model PREDICTED: ['astrostatistics tools', 'cosmology', 'markov chain monte carlo']\n",
      "\n",
      "--- FN Sample #3 (Original Index: 238) ---\n",
      "Title: Understanding Binary Systems-a Comparison between COSMIC and MESA\n",
      "  > Model's Confidence for 'gamma-ray bursts': 0.009\n",
      "  > Model PREDICTED: ['binary stars', 'close binary stars', 'common envelope binary stars', 'interacting binary stars', 'massive stars', 'multiple star evolution', 'stellar evolution', 'stellar evolutionary models', 'stellar mergers']\n",
      "================================================================================\n",
      "Error Analysis for Class: 'galaxies'\n",
      "(Threshold for this class: 0.045)\n",
      "================================================================================\n",
      "\n",
      "Found 300 False Positives.\n",
      "\n",
      "--- FP Sample #1 (Original Index: 2112) ---\n",
      "Title: Multiple Emission Lines of Hα Emitters at z ∼ 2.3 from the Broad- and Medium-band Photometry in the ZFOURGE Survey\n",
      "  > Model's Confidence for 'galaxies': 0.098\n",
      "  > TRUE labels: ('emission line galaxies', 'galaxy evolution', 'high-redshift galaxies')\n",
      "\n",
      "--- FP Sample #2 (Original Index: 998) ---\n",
      "Title: CLEAR: The Morphological Evolution of Galaxies in the Green Valley\n",
      "  > Model's Confidence for 'galaxies': 0.194\n",
      "  > TRUE labels: ('galaxy evolution', 'galaxy quenching', 'galaxy spectroscopy')\n",
      "\n",
      "--- FP Sample #3 (Original Index: 1148) ---\n",
      "Title: Ground- and Space-based Dust Observations of VV 191 Overlapping Galaxy Pair\n",
      "  > Model's Confidence for 'galaxies': 0.104\n",
      "  > TRUE labels: ('disk galaxies', 'emission line galaxies', 'galaxy spectroscopy', 'interstellar dust', 'interstellar dust extinction', 'interstellar medium')\n",
      "\n",
      "Found 16 False Negatives.\n",
      "\n",
      "--- FN Sample #1 (Original Index: 2503) ---\n",
      "Title: ULTRASAT: A Wide-field Time-domain UV Space Telescope\n",
      "  > Model's Confidence for 'galaxies': 0.012\n",
      "  > Model PREDICTED: ['astronomical methods', 'astrostatistics tools', 'gravitational wave astronomy', 'ground-based astronomy', 'light curves', 'markov chain monte carlo', 'observational astronomy', 'optical astronomy', 'optical observation', 'sky surveys', 'supernovae', 'surveys', 'telescopes', 'time domain astronomy', 'transient detection', 'transient sources', 'wide-field telescopes']\n",
      "\n",
      "--- FN Sample #2 (Original Index: 2198) ---\n",
      "Title: Identification of Galaxy Protoclusters Based on the Spherical Top-hat Collapse Theory\n",
      "  > Model's Confidence for 'galaxies': 0.045\n",
      "  > Model PREDICTED: ['cosmological evolution', 'high-redshift galaxy clusters', 'large-scale structure of the universe', 'n-body simulations']\n",
      "\n",
      "--- FN Sample #3 (Original Index: 675) ---\n",
      "Title: The Importance of Having an Extended Point-spread Function in Low Surface-brightness Science\n",
      "  > Model's Confidence for 'galaxies': 0.015\n",
      "  > Model PREDICTED: ['astronomical methods', 'astronomy data analysis', 'astronomy databases', 'atmospheric effects', 'broad band photometry', 'catalogs', 'ground-based astronomy', 'markov chain monte carlo', 'multi-color photometry', 'near infrared astronomy', 'optical observation', 'photometry', 'sky surveys', 'spectrophotometry', 'surveys', 'telescopes']\n"
     ]
    }
   ],
   "source": [
    "# --- 1.3 Run Analysis on Specific Classes (Corrected) ---\n",
    "\n",
    "# Get the original validation dataframe\n",
    "val_original_df = pd.DataFrame(dataset['val'])\n",
    "\n",
    "# --- Analyze a class where the Transformer performs MUCH better than the baseline ---\n",
    "# Find a class with good support and a high F1-score\n",
    "high_performing_classes = transformer_report_df[\n",
    "    (transformer_report_df['support'] > 50) & \n",
    "    (transformer_report_df['f1-score'] > 0.7) & \n",
    "    # This is the key fix: Exclude summary rows\n",
    "    (transformer_report_df.index.isin(mlb.classes_))\n",
    "]\n",
    "if not high_performing_classes.empty:\n",
    "    good_class = high_performing_classes.sort_values('f1-score', ascending=False).index[0]\n",
    "    analyze_transformer_errors(val_original_df, all_labels, all_preds, all_probs, mlb, good_class)\n",
    "else:\n",
    "    print(\"\\nCould not find a high-performing class with >50 support and >0.7 F1 to analyze.\")\n",
    "\n",
    "# --- Analyze a class where the Transformer still struggles ---\n",
    "# Find a class with high support but a low F1-score, EXCLUDING summary rows\n",
    "problematic_classes = transformer_report_df[\n",
    "    (transformer_report_df['support'] > 50) & \n",
    "    (transformer_report_df['f1-score'] < 0.5) & \n",
    "    # This is the key fix: Exclude summary rows\n",
    "    (transformer_report_df.index.isin(mlb.classes_))\n",
    "]\n",
    "if not problematic_classes.empty:\n",
    "    problem_class = problematic_classes.sort_values('f1-score').index[0]\n",
    "    analyze_transformer_errors(val_original_df, all_labels, all_preds, all_probs, mlb, problem_class)\n",
    "else:\n",
    "    print(\"\\nNo highly problematic classes found with >50 support and <0.5 F1 to analyze.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
